{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8afa686a-8581-434a-b02e-aff0fb97ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# XGBoost Classification (XGB) Experiment\n",
    "# ==============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import xgboost as xgb  # Make sure you have this installed: pip install xgboost\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from preprocessing import prepare_data\n",
    "\n",
    "# Experiment config\n",
    "random_state = 42\n",
    "results = []\n",
    "partial_save_path = \"results/xgb_partial_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3722ae-93ab-49d1-a8ae-007e3ad75849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train/test data.\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# 1. Load Data\n",
    "# ---\n",
    "train_df = pd.read_csv(\"fraudTrain.csv\")\n",
    "test_df = pd.read_csv(\"fraudTest.csv\")\n",
    "\n",
    "print(\"Loaded train/test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76616535-448b-412b-a81c-87fd8de671ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set prepared for trees. Shape: (555719, 13)\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# 2. Prepare Data for TREE Models\n",
    "# ---\n",
    "# We MUST use mode=\"tree\". This skips scaling and uses OrdinalEncoders.\n",
    "out_train_init = prepare_data(\n",
    "    train_df,\n",
    "    mode=\"tree\",\n",
    "    training=False,  # We only need the encoders\n",
    "    fit=True,\n",
    ")\n",
    "encoders = out_train_init[\"encoders\"]\n",
    "scalers = {}  # Scalers are not used\n",
    "\n",
    "# Prepare TEST set using the *same* \"tree\" mode\n",
    "out_test = prepare_data(\n",
    "    test_df,\n",
    "    mode=\"tree\",\n",
    "    training=False,\n",
    "    fit=False,\n",
    "    encoders=encoders,\n",
    "    scalers=scalers,\n",
    ")\n",
    "df_test = out_test[\"df\"]\n",
    "X_test = df_test.drop(\"is_fraud\", axis=1)\n",
    "y_test = df_test[\"is_fraud\"]\n",
    "\n",
    "# Clean inf/-inf values\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0).clip(-1e6, 1e6)\n",
    "\n",
    "print(f\"Test set prepared for trees. Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7185884e-3ea8-4160-8c15-34c9dc924927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# 3. Define Experiment Parameters\n",
    "# ---\n",
    "# Based on ALL previous results, we are only testing the best ratios.\n",
    "ratios_to_test = [0.05, 0.1, 0.2] \n",
    "resample_types_to_test = [\"df_up\", \"df_down\"] \n",
    "\n",
    "# XGBoost specific parameters\n",
    "# 'scale_pos_weight' is how XGBoost handles imbalance *internally*.\n",
    "# We will test both our external resampling (what we've been doing)\n",
    "# and its internal method.\n",
    "params_to_test = [\n",
    "    {\n",
    "        \"name\": \"XGB_Resampled\", # Our method\n",
    "        \"params\": {\n",
    "            \"n_estimators\": 200, # More trees\n",
    "            \"max_depth\": 10,       # Based on RF, deep trees are fine\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": random_state,\n",
    "            \"scale_pos_weight\": 1 # <-- We are handling balance with resampling\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"XGB_Depth_None\", # Your new \"unconstrained\" experiment\n",
    "        \"params\": {\n",
    "            \"n_estimators\": 200,\n",
    "            \"max_depth\": None,     # <-- No limit. This is your change.\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": random_state,\n",
    "            \"scale_pos_weight\": 1\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a7735b8-9626-437b-89c3-2277e6c9d8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting XGBoost experiment loop...\n",
      "\n",
      "======================================================================\n",
      "[23:51:22] Starting ratio 1/3 â†’ ratio=0.05\n",
      "  [23:51:26] â†’ Training on df_up (samples=1,353,627)\n",
      "    â³ Running XGB_Resampled ... done â†’ F1=0.8475, Recall=0.7874, AUC=0.9969 | Time=30.4s\n",
      "  [23:51:57] â†’ Training on df_down (samples=157,626)\n",
      "    â³ Running XGB_Resampled ... done â†’ F1=0.7620, Recall=0.8573, AUC=0.9973 | Time=7.2s\n",
      "  ðŸ’¾ Saved intermediate results â†’ results/xgb_partial_results.csv\n",
      "  âœ… Completed ratio=0.05 in 0.7 min\n",
      "\n",
      "======================================================================\n",
      "[23:52:04] Starting ratio 2/3 â†’ ratio=0.1\n",
      "  [23:52:07] â†’ Training on df_up (samples=1,418,086)\n",
      "    â³ Running XGB_Resampled ... done â†’ F1=0.8513, Recall=0.8005, AUC=0.9968 | Time=33.7s\n",
      "  [23:52:41] â†’ Training on df_down (samples=82,566)\n",
      "    â³ Running XGB_Resampled ... done â†’ F1=0.6325, Recall=0.9002, AUC=0.9973 | Time=4.8s\n",
      "  ðŸ’¾ Saved intermediate results â†’ results/xgb_partial_results.csv\n",
      "  âœ… Completed ratio=0.1 in 0.7 min\n",
      "\n",
      "======================================================================\n",
      "[23:52:46] Starting ratio 3/3 â†’ ratio=0.2\n",
      "  [23:52:50] â†’ Training on df_up (samples=1,547,003)\n",
      "    â³ Running XGB_Resampled ... done â†’ F1=0.8460, Recall=0.8065, AUC=0.9971 | Time=28.9s\n",
      "  [23:53:19] â†’ Training on df_down (samples=45,036)\n",
      "    â³ Running XGB_Resampled ... done â†’ F1=0.4999, Recall=0.9343, AUC=0.9972 | Time=4.2s\n",
      "  ðŸ’¾ Saved intermediate results â†’ results/xgb_partial_results.csv\n",
      "  âœ… Completed ratio=0.2 in 0.6 min\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# 4. Run Experiment Loop\n",
    "# ---\n",
    "print(\"\\nStarting XGBoost experiment loop...\")\n",
    "for ratio_idx, ratio in enumerate(ratios_to_test, start=1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\n",
    "        f\"[{datetime.now().strftime('%H:%M:%S')}] Starting ratio {ratio_idx}/{len(ratios_to_test)} â†’ ratio={ratio}\"\n",
    "    )\n",
    "    start_ratio_time = time.time()\n",
    "\n",
    "    out_train = prepare_data(\n",
    "        train_df,\n",
    "        mode=\"tree\",\n",
    "        training=True,\n",
    "        ratio=ratio,\n",
    "        fit=False,  \n",
    "        encoders=encoders,\n",
    "        scalers=scalers,\n",
    "    )\n",
    "\n",
    "    for resample_type in resample_types_to_test:\n",
    "        if resample_type not in out_train or out_train[resample_type] is None:\n",
    "            continue\n",
    "\n",
    "        df_train = out_train[resample_type]\n",
    "        X_train = df_train.drop(\"is_fraud\", axis=1)\n",
    "        y_train = df_train[\"is_fraud\"]\n",
    "\n",
    "        X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0).clip(-1e6, 1e6)\n",
    "\n",
    "        print(\n",
    "            f\"  [{datetime.now().strftime('%H:%M:%S')}] â†’ Training on {resample_type} (samples={len(X_train):,})\"\n",
    "        )\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        for p_info in params_to_test:\n",
    "            model_name = p_info[\"name\"]\n",
    "            params = p_info[\"params\"]\n",
    "            start_k_time = time.time()\n",
    "\n",
    "            print(f\"    â³ Running {model_name} ...\", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            \n",
    "            model.fit(\n",
    "                X_train, \n",
    "                y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # Predict\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # Metrics\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # === FIX #1: Handle AttributeError ===\n",
    "            try:\n",
    "                best_iter = model.best_iteration\n",
    "            except AttributeError:\n",
    "                best_iter = model.n_estimators # Set to full run if no early stop\n",
    "            # =====================================\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model\": model_name,\n",
    "                    \"ratio\": ratio,\n",
    "                    \"resample_type\": resample_type.replace(\"df_\",\"\"),\n",
    "                    \"accuracy\": acc,\n",
    "                    \"precision\": prec,\n",
    "                    \"recall\": rec,\n",
    "                    \"f1\": f1,\n",
    "                    \"roc_auc\": auc,\n",
    "                    \"best_iter\": best_iter\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\" done â†’ F1={f1:.4f}, Recall={rec:.4f}, AUC={auc:.4f} | Time={time.time() - start_k_time:.1f}s\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    pd.DataFrame(results).to_csv(partial_save_path, index=False)\n",
    "    print(f\"  ðŸ’¾ Saved intermediate results â†’ {partial_save_path}\")\n",
    "    print(f\"  âœ… Completed ratio={ratio} in {(time.time() - start_ratio_time)/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e157339e-a374-4fc8-9b56-512cb8bfbe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "[23:54:22] Starting Internal Imbalance Handling (scale_pos_weight)\n",
      "  Using original training data (samples=1,296,675)\n",
      "  Calculated scale_pos_weight: 171.75 (Legit: 1289169, Fraud: 7506)\n",
      "    â³ Running XGB_Internal_ScalePos ... done â†’ F1=0.8069, Recall=0.8065, AUC=0.9959 | Time=22.9s\n",
      "  ðŸ’¾ Saved intermediate results â†’ results/xgb_partial_results.csv\n",
      "  âœ… Completed internal run in 0.4 min\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# 5. Add the \"Internal Resampling\" Experiment (API FIX)\n",
    "# ---\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Starting Internal Imbalance Handling (scale_pos_weight)\")\n",
    "start_ratio_time = time.time()\n",
    "\n",
    "out_train_orig = prepare_data(\n",
    "    train_df,\n",
    "    mode=\"tree\",\n",
    "    training=True,\n",
    "    ratio=None, \n",
    "    fit=False,  \n",
    "    encoders=encoders,\n",
    "    scalers=scalers,\n",
    ")\n",
    "\n",
    "df_train_orig = out_train_orig[\"df_up\"] \n",
    "X_train_orig = df_train_orig.drop(\"is_fraud\", axis=1)\n",
    "y_train_orig = df_train_orig[\"is_fraud\"]\n",
    "\n",
    "X_train_orig = X_train_orig.replace([np.inf, -np.inf], np.nan).fillna(0).clip(-1e6, 1e6)\n",
    "\n",
    "n_legit = (y_train_orig == 0).sum()\n",
    "n_fraud = (y_train_orig == 1).sum()\n",
    "imbalance_ratio = n_legit / n_fraud\n",
    "print(f\"  Using original training data (samples={len(X_train_orig):,})\")\n",
    "print(f\"  Calculated scale_pos_weight: {imbalance_ratio:.2f} (Legit: {n_legit}, Fraud: {n_fraud})\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "model_name = \"XGB_Internal_ScalePos\"\n",
    "# === API FIX: MOVED PARAMS HERE ===\n",
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": 10,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": random_state,\n",
    "    \"scale_pos_weight\": imbalance_ratio,\n",
    "    \"early_stopping_rounds\": 20,\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "\n",
    "start_k_time = time.time()\n",
    "print(f\"    â³ Running {model_name} ...\", end=\"\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "# === API FIX: Removed early_stopping_rounds from .fit() ===\n",
    "model.fit(\n",
    "    X_train_orig, \n",
    "    y_train_orig,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Predict & Metrics\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "results.append(\n",
    "    {\n",
    "        \"model\": model_name,\n",
    "        \"ratio\": \"internal\", \n",
    "        \"resample_type\": \"none\",\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": auc,\n",
    "        # === API FIX: Use .best_iteration attribute ===\n",
    "        \"best_iter\": model.best_iteration\n",
    "    }\n",
    ")\n",
    "print(\n",
    "    f\" done â†’ F1={f1:.4f}, Recall={rec:.4f}, AUC={auc:.4f} | Time={time.time() - start_k_time:.1f}s\"\n",
    ")\n",
    "print(f\"  ðŸ’¾ Saved intermediate results â†’ {partial_save_path}\")\n",
    "print(f\"  âœ… Completed internal run in {(time.time() - start_ratio_time)/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23025a1e-5beb-496a-915d-bbf0567adad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All ratios completed.\n",
      "Total experiments logged: 7\n",
      "\n",
      "--- Top Performing XGBoost Models ---\n",
      "                   model     ratio resample_type  accuracy  precision  \\\n",
      "2          XGB_Resampled       0.1            up  0.998920   0.908947   \n",
      "0          XGB_Resampled      0.05            up  0.998906   0.917436   \n",
      "4          XGB_Resampled       0.2            up  0.998866   0.889460   \n",
      "6  XGB_Internal_ScalePos  internal          none  0.998510   0.807280   \n",
      "1          XGB_Resampled      0.05          down  0.997932   0.685682   \n",
      "3          XGB_Resampled       0.1          down  0.995962   0.487503   \n",
      "5          XGB_Resampled       0.2          down  0.992784   0.341223   \n",
      "\n",
      "     recall        f1   roc_auc  best_iter  \n",
      "2  0.800466  0.851264  0.996830        200  \n",
      "0  0.787413  0.847466  0.996908        200  \n",
      "4  0.806527  0.845966  0.997123        200  \n",
      "6  0.806527  0.806903  0.995876        198  \n",
      "1  0.857343  0.761964  0.997330        200  \n",
      "3  0.900233  0.632493  0.997302        200  \n",
      "5  0.934266  0.499875  0.997176        200  \n",
      "\n",
      "Saved final results to results/xgb_results.csv\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# 6. Show Final Results\n",
    "# ---\n",
    "print(\"\\nAll ratios completed.\")\n",
    "print(f\"Total experiments logged: {len(results)}\")\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"f1\", ascending=False)\n",
    "print(\"\\n--- Top Performing XGBoost Models ---\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "results_df.to_csv(\"results/xgb_results.csv\", index=False)\n",
    "print(\"\\nSaved final results to results/xgb_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d34afb3e-f100-4e8c-81cd-1f3e0fb60fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Starting 'XGB_Depth_None' ONLY experiment loop...\n",
      "======================================================================\n",
      "\n",
      "[16:40:50] Starting ratio 1/3 â†’ ratio=0.05\n",
      "  [16:40:58] â†’ Training on df_up (samples=1,353,627)\n",
      "    â³ Running XGB_Depth_None ... done â†’ F1=0.8164, Recall=0.8238, AUC=0.9973 | Time=43.2s\n",
      "  [16:41:41] â†’ Training on df_down (samples=157,626)\n",
      "    â³ Running XGB_Depth_None ... done â†’ F1=0.7670, Recall=0.8480, AUC=0.9975 | Time=17.2s\n",
      "  ðŸ’¾ Saved intermediate results â†’ results/xgb_partial_results.csv\n",
      "  âœ… Completed ratio=0.05 in 1.1 min\n",
      "\n",
      "[16:41:58] Starting ratio 2/3 â†’ ratio=0.1\n",
      "  [16:42:06] â†’ Training on df_up (samples=1,418,086)\n",
      "    â³ Running XGB_Depth_None ... done â†’ F1=0.7630, Recall=0.8606, AUC=0.9976 | Time=29.7s\n",
      "  [16:42:35] â†’ Training on df_down (samples=82,566)\n",
      "    â³ Running XGB_Depth_None ... done â†’ F1=0.6487, Recall=0.8881, AUC=0.9973 | Time=4.0s\n",
      "  ðŸ’¾ Saved intermediate results â†’ results/xgb_partial_results.csv\n",
      "  âœ… Completed ratio=0.1 in 0.7 min\n",
      "\n",
      "[16:42:39] Starting ratio 3/3 â†’ ratio=0.2\n",
      "  [16:42:42] â†’ Training on df_up (samples=1,547,003)\n",
      "    â³ Running XGB_Depth_None ... done â†’ F1=0.6933, Recall=0.8928, AUC=0.9977 | Time=18.0s\n",
      "  [16:43:00] â†’ Training on df_down (samples=45,036)\n",
      "    â³ Running XGB_Depth_None ... done â†’ F1=0.5253, Recall=0.9249, AUC=0.9973 | Time=3.5s\n",
      "  ðŸ’¾ Saved intermediate results â†’ results/xgb_partial_results.csv\n",
      "  âœ… Completed ratio=0.2 in 0.4 min\n",
      "\n",
      "âœ… 'XGB_Depth_None' experiments are complete and added to results.\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# 5. Run 'XGB_Depth_None' Experiment\n",
    "# ---\n",
    "# This cell ONLY tests the 'max_depth=None' (unconstrained) model\n",
    "# to compare against the 'max_depth=10' models from the cell above.\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Starting 'XGB_Depth_None' ONLY experiment loop...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Define ONLY the new parameters to test\n",
    "params_to_test_new = [\n",
    "    {\n",
    "        \"name\": \"XGB_Depth_None\", # The \"unconstrained\" experiment\n",
    "        \"params\": {\n",
    "            \"n_estimators\": 200,\n",
    "            \"max_depth\": None,     # <-- No limit\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": random_state,\n",
    "            \"scale_pos_weight\": 1\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# This loop is identical to the one above, but uses 'params_to_test_new'\n",
    "for ratio_idx, ratio in enumerate(ratios_to_test, start=1):\n",
    "    print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Starting ratio {ratio_idx}/{len(ratios_to_test)} â†’ ratio={ratio}\")\n",
    "    start_ratio_time = time.time()\n",
    "\n",
    "    # Get the pre-processed data for this ratio\n",
    "    out_train = prepare_data(\n",
    "        train_df,\n",
    "        mode=\"tree\",\n",
    "        training=True,\n",
    "        ratio=ratio,\n",
    "        fit=False,  \n",
    "        encoders=encoders,\n",
    "        scalers=scalers,\n",
    "    )\n",
    "\n",
    "    for resample_type in resample_types_to_test:\n",
    "        if resample_type not in out_train or out_train[resample_type] is None:\n",
    "            continue\n",
    "\n",
    "        df_train = out_train[resample_type]\n",
    "        X_train = df_train.drop(\"is_fraud\", axis=1)\n",
    "        y_train = df_train[\"is_fraud\"]\n",
    "\n",
    "        X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0).clip(-1e6, 1e6)\n",
    "\n",
    "        print(\n",
    "            f\"  [{datetime.now().strftime('%H:%M:%S')}] â†’ Training on {resample_type} (samples={len(X_train):,})\"\n",
    "        )\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Iterate over our ONE new model config\n",
    "        for p_info in params_to_test_new:\n",
    "            model_name = p_info[\"name\"]\n",
    "            params = p_info[\"params\"]\n",
    "            start_k_time = time.time()\n",
    "\n",
    "            print(f\"    â³ Running {model_name} ...\", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            \n",
    "            model.fit(\n",
    "                X_train, \n",
    "                y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # Predict\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # Metrics\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            rec = recall_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "            prec = precision_score(y_test, y_pred)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            try:\n",
    "                best_iter = model.best_iteration\n",
    "            except AttributeError:\n",
    "                best_iter = model.n_estimators\n",
    "\n",
    "            # Append to the *SAME* results list\n",
    "            results.append(\n",
    "                {\n",
    "                    \"model\": model_name,\n",
    "                    \"ratio\": ratio,\n",
    "                    \"resample_type\": resample_type.replace(\"df_\",\"\"),\n",
    "                    \"accuracy\": acc,\n",
    "                    \"precision\": prec,\n",
    "                    \"recall\": rec,\n",
    "                    \"f1\": f1,\n",
    "                    \"roc_auc\": auc,\n",
    "                    \"best_iter\": best_iter\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\" done â†’ F1={f1:.4f}, Recall={rec:.4f}, AUC={auc:.4f} | Time={time.time() - start_k_time:.1f}s\"\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    pd.DataFrame(results).to_csv(partial_save_path, index=False)\n",
    "    print(f\"  ðŸ’¾ Saved intermediate results â†’ {partial_save_path}\")\n",
    "    print(f\"  âœ… Completed ratio={ratio} in {(time.time() - start_ratio_time)/60:.1f} min\")\n",
    "\n",
    "print(\"\\nâœ… 'XGB_Depth_None' experiments are complete and added to results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96b3f88-6f12-4c52-b813-b11f39240fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = out_train_init[\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c682adf9-699e-48fa-ba0b-61d808862f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>age</th>\n",
       "      <th>distance_from_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>514</td>\n",
       "      <td>8</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>78.597568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>241</td>\n",
       "      <td>4</td>\n",
       "      <td>107.23</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>30.212176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>220.11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>108.206083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>2</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>95.673231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297</td>\n",
       "      <td>9</td>\n",
       "      <td>41.96</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>77.556744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296670</th>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>15.56</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>119.752136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296671</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>51.70</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>75.104085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296672</th>\n",
       "      <td>599</td>\n",
       "      <td>1</td>\n",
       "      <td>105.93</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>99.047734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296673</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>74.90</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>84.627652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296674</th>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>83.853655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296675 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         merchant  category     amt  gender  state  city_pop  is_fraud  hour  \\\n",
       "0             514         8    4.97       0     27      3495         0     0   \n",
       "1             241         4  107.23       0     47       149         0     0   \n",
       "2             390         0  220.11       1     13      4154         0     0   \n",
       "3             360         2   45.00       1     26      1939         0     0   \n",
       "4             297         9   41.96       1     45        99         0     0   \n",
       "...           ...       ...     ...     ...    ...       ...       ...   ...   \n",
       "1296670       499         0   15.56       1     44       258         0    12   \n",
       "1296671         2         1   51.70       1     20       100         0    12   \n",
       "1296672       599         1  105.93       1     32       899         0    12   \n",
       "1296673       509         1   74.90       1     41      1126         0    12   \n",
       "1296674       370         1    4.30       1     26       218         0    12   \n",
       "\n",
       "         day  month  weekday  is_weekend  age  distance_from_home  \n",
       "0          1      1        1           0   31           78.597568  \n",
       "1          1      1        1           0   41           30.212176  \n",
       "2          1      1        1           0   57          108.206083  \n",
       "3          1      1        1           0   52           95.673231  \n",
       "4          1      1        1           0   33           77.556744  \n",
       "...      ...    ...      ...         ...  ...                 ...  \n",
       "1296670   21      6        6           1   59          119.752136  \n",
       "1296671   21      6        6           1   41           75.104085  \n",
       "1296672   21      6        6           1   53           99.047734  \n",
       "1296673   21      6        6           1   40           84.627652  \n",
       "1296674   21      6        6           1   25           83.853655  \n",
       "\n",
       "[1296675 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76276cac-0d15-4bbe-b4d2-917dfbed7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_AMT = 47.52\n",
      "DEFAULT_CITY_POP = 2456\n",
      "DEFAULT_AGE = 44\n",
      "DEFAULT_DISTANCE = 78.23\n"
     ]
    }
   ],
   "source": [
    "# For Amount\n",
    "print(f\"DEFAULT_AMT = {df_train['amt'].median():.2f}\")\n",
    "\n",
    "# For City Population\n",
    "print(f\"DEFAULT_CITY_POP = {df_train['city_pop'].median():.0f}\")\n",
    "\n",
    "# For Age\n",
    "print(f\"DEFAULT_AGE = {df_train['age'].median():.0f}\")\n",
    "\n",
    "# For Distance\n",
    "print(f\"DEFAULT_DISTANCE = {df_train['distance_from_home'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be14c70-865e-4c43-8725-89fd4925b59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
